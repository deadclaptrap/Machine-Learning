# -*- coding: utf-8 -*-
"""Бригада_9.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1cZVNqfyZ2yo9PB01Q139OBTwRWK--tq7

##Подключение необходимых библиотек
"""

import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
import scipy.stats as sps
import warnings
from tabulate import tabulate
warnings.filterwarnings('ignore')

from google.colab import drive
drive.mount('/content/drive')

"""##Чтение и подготовка данных"""

df = pd.read_csv("/content/Salary.csv")
df["Age"] = df["Age"].astype(int)
df["Years of Experience"] = df["Years of Experience"].astype(int)
df["Gender"] = df["Gender"].astype('category')
df["Job Title"] = df["Job Title"].astype('category')
df["Country"] = df["Country"].astype('category')
df["Race"] = df["Race"].astype('category')
df["Senior"] = df["Senior"].replace({0:"No", 1: "Yes"}).astype('category')
df["Education Level"] = df["Education Level"]\
                        .replace({0:"High School", 1: "Bachelor Degree", 2:"Master Degree", 3: "Phd"})\
                        .astype('category')

df.head()

df.tail()

df.dtypes

print(f"DataFrame Shape: {df.shape}")

unique_counts = pd.DataFrame.from_records([(col, df[col].nunique()) for col in df.columns],
                                          columns=['Column_Name', 'Num_Unique']).sort_values(by=['Num_Unique'])
unique_counts

unique_counts[unique_counts['Column_Name'] == 'Job Title']

df_tmp = pd.DataFrame(df['Job Title'].value_counts())
df_tmp.reset_index(inplace= True )
plt.bar(df_tmp['Job Title'], df_tmp['count'])
plt.xticks(rotation=90)
plt.show()

job_technology = ['Software Engineer', 'Software Developer', 'IT Support',
          'Network Engineer', 'Web Developer', 'Web Designer', 'IT Manager', 'IT Support Specialist',
          'IT Project Manager', 'IT Consultant', 'Software Architect', 'Back end Developer',
          'Full Stack Engineer', 'Front end Developer', 'Developer', 'Front End Developer', 'Back End Developer']

job_analyze = ['Data Analyst', 'Marketing Analyst', 'Business Analyst', 'Data Scientist',
               'Business Intelligence Analyst', 'Supply Chain Analyst',
               'Quality Assurance Analyst', 'Financial Analyst', 'Data Engineer', 'Operations Analyst',
               'Data Entry Clerk', 'Training Specialist', 'Business Operations Analyst']

job_control = ['Software Engineer Manager', 'Manager', 'Director', 'VP of Operations', 'VP of Finance', 'Chief Technology Officer',
               'Chief Data Officer', 'Director of Marketing', 'Director of Operations', 'Director of Sales and Marketing',
               'Director of Human Resources', 'Director of Product Management', 'Director of Business Development',
               'Director of Engineering', 'Director of HR', 'Director of Data Science', 'Research Director',
               'Operations Manager', 'Operations Coordinator', 'Operations Analyst', 'Supply Chain Manager',
               'Administrative Assistant', 'Director of Finance', 'Office Manager', 'Product Development Manager',
               'Product Manager', 'Creative Director', 'Human Resources Director', 'Sales Director', 'Operations Director',
               'Director of Finance', 'Director of Human Capital', 'CEO', 'Director of Data Science',
               'HR Manager', 'HR Generalist', 'HR Coordinator', 'HR Specialist', 'Juniour HR Generalist',
               'Juniour HR Coordinator', 'Human Resources Manager', 'Human Resources Coordinator', 'Human Resources Specialist',
               'Chief Data Officer', 'Project Manager', 'Software Manager', 'Software Project Manager', 'Marketing Director']

job_marketing = ['Marketing Manager', 'Marketing Coordinator', 'Marketing Manager',
                 'Marketing Specialist', 'Social Media Specialist', 'Copywriter', 'Digital Marketing Manager',
                 'Product Marketing Manager', 'Advertising Coordinator',
                 'Sales Representative', 'Account Executive', 'Digital Marketing Specialist',
                 'Social Media Manager', 'Content Marketing Manager', 'Social Media Specialist', 'Strategy Consultant',
                 'Account Manager']

job_creativity = ['Digital Content Producer', 'Product Designer', 'Graphic Designer', 'UX Researcher', 'Copywriter', 'Technical Writer',
                  'Project Engineer', 'Designer', 'UX Designer']

job_client = ['Customer Service Rep', 'Customer Success Rep', 'Customer Service Manager',
              'Customer Support Specialist', 'Customer Success Manager','Receptionist',
              'Delivery Driver', 'Public Relations Manager',
              'Event Coordinator', 'Help Desk Analyst', 'Customer Service Manager',
              'Customer Service Representative', 'Technical Recruiter', 'Technical Support Specialist',
              'Recruiter', 'Receptionist', 'Social Media Man', 'Delivery Driver']

job_consult = ['Sales Executive', 'Director of Sales', 'Financial Manager', 'Accountant', 'Financial Advisor', 'Strategy Consultant', 'Consultant',
                'Business Development Manager', 'Business Development Associate', 'Financial Advisor',
               'Sales Manager', 'Sales Operations Manager', 'Product Development Manager', 'Sales Associate']

job_science = ['Engineer', 'Scientist', 'Principal Scientist', 'Research Scientist', 'Researcher',
               'Project Coordinator', 'Event Coordinator', 'Public Relations Manager',
               'Operations Coordinator', 'Product Development Manager', 'Principal Engineer']

job_catalog = ['job_technology', 'job_analyze', 'job_control', 'job_marketing', 'job_creativity', 'job_client', 'job_consult', 'job_science']
job_1 = [job_technology, job_analyze, job_control, job_marketing, job_creativity, job_client, job_consult, job_science]

list_job = list(df['Job Title'])

for p in range(len(list_job)):
  for n in job_catalog:
    if list_job[p] in job_1[job_catalog.index(n)]:
      list_job[p] = n
      break

df_job_group = pd.DataFrame({"Job Group": list_job})
df_job_group = pd.concat([df, df_job_group], axis=1)
df_job_group = df_job_group.drop(columns=['Job Title'])
df_job_group["Job Group"] = df_job_group["Job Group"].astype('category')

df_tmp = pd.DataFrame(df_job_group['Job Group'].value_counts())
df_tmp.reset_index(inplace= True )
plt.bar(df_tmp['Job Group'], df_tmp['count'])
plt.xticks(rotation=90)
plt.show()

"""##Описательная статистика"""

def describe_column(dataframe, column_name, i):
    data = dataframe[column_name]
    cnt, mean, std, *quartiles = data.describe()
    x_min, lower_quartile, x_median, upper_quartile, x_max = quartiles
    interquartile_range = upper_quartile - lower_quartile
    df_isna = list(dataframe.isna().sum())
    skewness = sps.skew(data)
    kurtosis = sps.kurtosis(data)
    return {
        "Переменная":column_name,
        "Среднее": mean,
        "Медиана": x_median,
        "Стандартное отклонение":std,
        "Межквартильный размах": interquartile_range,
        "Верхняя квартиль": upper_quartile,
        "Нижняя квартиль": lower_quartile,
        "Коэффициент асимметрии": skewness,
        "Коэффициент эксцесса": kurtosis,
        "Минимальное значение": x_min,
        "Максимальное значение": x_max,
        "Количество наблюдений": cnt,
        "Количество пропущенных значений": df_isna[i]}

numerical_columns = [
    'Age',
    'Years of Experience',
    'Salary'
]

quality_columns = list(set(df_job_group.columns) - set(numerical_columns))

descr_df_1 = []
i = 0
for n in numerical_columns:
  descr_df_1.append(describe_column(df, n, i))
  i += 1

pd.DataFrame(descr_df_1).set_index(['Переменная']).transpose()

df_tmp = df.select_dtypes(include=["float", "int"])
discr_df = df_tmp.describe()
w = df_tmp.quantile(q=0.75) - df_tmp.quantile(q=0.25)
df_w = pd.DataFrame([w], index=['IQR'])
df_isna = pd.DataFrame([df_tmp.isna().sum()], index=['Count of Null values'])
discr_df = pd.concat([discr_df, df_w])
discr_df = pd.concat([discr_df, df_w])
discr_df

"""##Выбросы"""

print('\033[1mCount of outliers for numerical values\033[0m')
for col in numerical_columns:
  irq = df_w[col]
  wisker_u = (discr_df.loc['75%', col] + 1.5*irq).values[0]
  wisker_l = (discr_df.loc['25%', col] - 1.5*irq).values[0]
  sel = (df_tmp[col] > wisker_u) + (df_tmp[col] <= wisker_l)
  out = df_tmp.loc[sel, :]
  print(f'\033[1m{col} outlier: \033[0m{len(out)}')

fig, axes = plt.subplots(1, 2, figsize=(12, 6))

sns.boxplot(x=df["Age"], ax=axes[0])
axes[0].set_title("Box-plot of 'Age'")

sns.boxplot(x=df["Years of Experience"], ax=axes[1])
axes[1].set_title("Box-plot of 'Years of Experience'")

plt.tight_layout()

plt.show()

"""##Избавление от бимодальности с помощью разбиения на две группы

"""

dfn = df_job_group.select_dtypes(include=['int', 'float64'])
# Не рекомендуется. Простейший вариант.
#dfn.hist(bins='fd', density=True, grid=True, legend=False, color=None)
# Рекомендуется. Размещение на листе (Pandas и Matplotlib).
# Не более, чем по три графика в столбце
nrow = dfn.shape[1]
fig, ax_lst = plt.subplots(nrow, 1)
fig.figsize=(15, 9) # Дюймы
nplt = -1
tit = {'Age':'Возраст', 'Education Level': "Уровень образования", "Years of Experience": "Опыт работы", "Salary": "Зарплата"}
for nplt, s in enumerate(dfn.columns):
    # ax_lst[nplt].hist(dfn[[s]], bins='fd', density=True, color=None)
    dfn.hist(column=s, ax=ax_lst[nplt], bins='fd', density=True, grid=True,
             legend=False, color=None)
#    ax_lst[nplt].hist(dfn[s], bins='fd', density=True, color='darkkhaki')
    # ax_lst[nplt].grid(visible=True)
    ax_lst[nplt].set_title(tit[s], fontdict={'fontsize':15, 'color':'blue'}, loc='left')
fig.subplots_adjust(wspace=0.5, hspace=1.0)
fig.suptitle(f'Гистограммы переменных {list(dfn.columns)}')
plt.savefig('/content/drive/MyDrive/graphics/jobs_qnt.pdf', format='pdf')
plt.show()

fig, axs = plt.subplots(3, 1, figsize=(12, 6))

sns.histplot(df_job_group["Age"], kde=True, ax=axs[0])
axs[0].set_title("Age Distribution")

sns.histplot(df_job_group["Years of Experience"], kde=True, ax=axs[1])
axs[1].set_title("Years of Experience Distribution")

sns.histplot(df_job_group["Salary"], kde=True, ax=axs[2])
axs[2].set_title("Salary")

plt.tight_layout()
plt.savefig('/content/drive/MyDrive/graphics/jobs_qnt_2.pdf', format='pdf')

plt.show()

df_job_group_poor = df_job_group[df_job_group['Salary'] <= 130000]
df_job_group_rich = df_job_group[df_job_group['Salary'] >= 140000]

fig, axs = plt.subplots(1, 2, figsize=(12, 6))

sns.histplot(df_job_group_poor["Salary"], kde=True, ax=axs[0])
axs[0].set_title("Salary poor employee")

sns.histplot(df_job_group_rich["Salary"], kde=True, ax=axs[1])
axs[1].set_title("Salary rich employee")

plt.tight_layout()
plt.savefig('/content/drive/MyDrive/graphics/jobs_qnt_pr.pdf', format='pdf')

plt.show()

def describe_column(dataframe, column_name, i, name):
    data = dataframe[column_name]
    cnt, mean, std, *quartiles = data.describe()
    x_min, lower_quartile, x_median, upper_quartile, x_max = quartiles
    interquartile_range = upper_quartile - lower_quartile
    df_isna = list(dataframe.isna().sum())
    skewness = sps.skew(data)
    kurtosis = sps.kurtosis(data)
    return {
        "Переменная":name,
        "Среднее": mean,
        "Медиана": x_median,
        "Стандартное отклонение":std,
        "Межквартильный размах": interquartile_range,
        "Верхняя квартиль": upper_quartile,
        "Нижняя квартиль": lower_quartile,
        "Коэффициент асимметрии": skewness,
        "Коэффициент эксцесса": kurtosis,
        "Минимальное значение": x_min,
        "Максимальное значение": x_max,
        "Количество наблюдений": cnt,
        "Количество пропущенных значений": df_isna[i]}

result = []
result.append(describe_column(df_job_group_poor, 'Salary', 0, 'Salary_lower_part'))
result.append(describe_column(df_job_group_rich, 'Salary', 1, 'Salary_upper_part'))
result = pd.DataFrame(result).set_index(['Переменная']).transpose()
result

"""##Описательная статистика для выбранного кластера"""

df_tmp = df_job_group_poor.select_dtypes(include=["float", "int"])
discr_df = df_tmp.describe()
w = df_tmp.quantile(q=0.75) - df_tmp.quantile(q=0.25)
df_w = pd.DataFrame([w], index=['IQR'])
df_isna = pd.DataFrame([df_tmp.isna().sum()], index=['Count of Null values'])
discr_df = pd.concat([discr_df, df_w])
discr_df

"""##Выбросы для выбранного кластера"""

print('\033[1mCount of outliers for numerical values\033[0m')
for col in numerical_columns:
  irq = df_w[col]
  wisker_u = (discr_df.loc['75%', col] + 1.5*irq).values[0]
  wisker_l = (discr_df.loc['25%', col] - 1.5*irq).values[0]
  sel = (df_tmp[col] > wisker_u) + (df_tmp[col] <= wisker_l)
  out = df_tmp.loc[sel, :]
  print(f'\033[1m{col} outlier: \033[0m{len(out)}')

fig, axes = plt.subplots(1, 2, figsize=(12, 6))

sns.boxplot(x=df_job_group_poor["Age"], ax=axes[0])
axes[0].set_title("Box-plot of 'Age'")

sns.boxplot(x=df_job_group_poor["Years of Experience"], ax=axes[1])
axes[1].set_title("Box-plot of 'Years of Experience'")

plt.tight_layout()
plt.savefig('/content/drive/MyDrive/graphics/jobs_outliers_poor.pdf', format='pdf')
plt.show()

"""##Анализ взаимосвязи"""

from scipy.stats import pearsonr, spearmanr, kendalltau

# Здесь будут значения значимости оценок коэффициента корреляции Пирсона
C_P = pd.DataFrame([], index=df_tmp.columns, columns=df_tmp.columns, dtype='float')
# Здесь будут значения значимости оценок коэффициента корреляции Пирсона
P_P = pd.DataFrame([], index=df_tmp.columns, columns=df_tmp.columns, dtype='float')
# Здесь будут значения оценок коэффициента корреляции Спирмена
C_S = pd.DataFrame([], index=df_tmp.columns, columns=df_tmp.columns, dtype='float')
# Здесь будут значения значимости оценок коэффициента корреляции Спирмена
P_S = pd.DataFrame([], index=df_tmp.columns, columns=df_tmp.columns, dtype='float')
# Здесь будут значения значимости оценок коэффициента корреляции Тау Кендалла
C_K = pd.DataFrame([], index=df_tmp.columns, columns=df_tmp.columns, dtype='float')
# Здесь будут значения значимости оценок коэффициента корреляции Тау Кендалла
P_K = pd.DataFrame([], index=df_tmp.columns, columns=df_tmp.columns, dtype='float')
for x in df_tmp.columns:
    for y in df_tmp.columns:
      C_P.loc[x,y], P_P.loc[x,y] = pearsonr(df_tmp[x], df_tmp[y])
      C_S.loc[x,y], P_S.loc[x,y] = spearmanr(df_tmp[x], df_tmp[y])
      C_K.loc[x,y], P_K.loc[x,y] = kendalltau(df_tmp[x], df_tmp[y])

with pd.ExcelWriter('/content/drive/MyDrive/output/JOB_STAT.xlsx', engine="openpyxl") as wrt:
# Общая статистика
    discr_df.to_excel(wrt, sheet_name='stat')
# Корреляция Пирсона
    C_P.to_excel(wrt, sheet_name='Pearson')
    dr = C_P.shape[0] + 2
    P_P.to_excel(wrt, startrow=dr, sheet_name='Pearson') # Значимость
# Корреляция Спирмена
    C_S.to_excel(wrt, sheet_name='Spirmen')
    dr = C_S.shape[0] + 2
    P_S.to_excel(wrt, startrow=dr, sheet_name='Spirmen') # Значимость
# Корреляция Тау Кендалла
    C_K.to_excel(wrt, sheet_name='Tau_Kendall')
    dr = C_K.shape[0] + 2
    P_K.to_excel(wrt, startrow=dr, sheet_name='Tau_Kendall') # Значимость

result = []
for n in numerical_columns:
  if n != 'Salary':
    result.append({'Переменная': n,
                   'Корреляция Пирсона': C_P.loc[n, 'Salary'],
                   'Pvalue корреляция Пирсона': P_P.loc[n, 'Salary'],
                   'Корреляция Спирмена': C_S.loc[n, 'Salary'],
                   'Pvalue корреляция Спирмена': P_S.loc[n, 'Salary'],
                   'Корреляция Кендалла тау': C_K.loc[n, 'Salary'],
                   'Pvalue корреляция Кендалла тау': P_K.loc[n, 'Salary']})

pd.DataFrame(result).set_index(['Переменная']).transpose()

result = []
result.append({'Переменная': 'Age-Years of Experience',
                   'Корреляция Пирсона': C_P.loc['Age', 'Years of Experience'],
                   'Pvalue корреляция Пирсона': P_P.loc['Age', 'Years of Experience'],
                   'Корреляция Спирмена': C_S.loc['Age', 'Years of Experience'],
                   'Pvalue корреляция Спирмена': P_S.loc['Age', 'Years of Experience'],
                   'Корреляция Кендалла тау': C_K.loc['Age', 'Years of Experience'],
                   'Pvalue корреляция Кендалла тау': P_K.loc['Age', 'Years of Experience']})

pd.DataFrame(result).set_index(['Переменная']).transpose()

"""## Анализ корреляции между количественной целевой переменной и качественной объясняющей"""

from scipy.stats import kruskal

def crusk_vals(nv, f):
      names = df_job_group_poor[nv].unique()
      res = []
      for val in names:
            val_true = df_job_group_poor[nv]== val
            res.append(df_job_group_poor.loc[val_true, 'Salary'])
      # Используем криетрий Крускала-Уоллиса
      salary_amount = kruskal(*res)
      # Сохраняем текстовый отчет
      with open('/content/drive/MyDrive/output/JOB_STAT.txt', 'a') as f:
            print(f'Критерий Крускала-Уоллиса для переменных \'Salary\' и \'{nv}\'',
                  file=f)
            print(salary_amount, file=f)

nom_vals = df_job_group_poor.select_dtypes(include=["category"])
with open('/content/drive/MyDrive/output/JOB_STAT.txt', 'w') as file_n:
      for name_val in nom_vals.columns:
            crusk_vals(name_val, file_n)

"""##Анализ взаимосвязи между двумя качественными показателями"""

import statsmodels.api as sm
from itertools import combinations
# Читаем и преобразуем данные
for left, right in combinations(nom_vals.columns, 2):
  crtx = pd.crosstab(df_job_group_poor[left], df_job_group_poor[right], margins=True)
  crtx.columns.name = right
  crtx.index.name = left + '\\' +right
  tabx = sm.stats.Table(crtx)
# Из уже готовой таблицы сопряженности
# Создаем объект sm.stats.Table для проведения анализа
# В объекте находятся все необходимые статистики и дополнительные методы
  # Альтернативный вариант создания sm.stats.Table
  #table = sm.stats.Table.from_data(CA[['music', 'signal']])
  # Сохраняем полученные результаты
  with pd.ExcelWriter('/content/drive/MyDrive/output/JOB_STAT.xlsx', engine="openpyxl",
                      if_sheet_exists='overlay', mode='a') as wrt:
  # Таблица сопряженности
      tabx.table_orig.to_excel(wrt, sheet_name=left + '-' + right)
      dr = tabx.table_orig.shape[0] + 2 # Смещение по строкам
  # Ожидаемые частоты при независимости
      tabx.fittedvalues.to_excel(wrt, sheet_name=left + '-' + right, startrow=dr)
  # Критерий хи квадрат для номинальных переменных
  resx = tabx.test_nominal_association()
  # Сохраняем результат в файле
  with open('/content/drive/MyDrive/output/JOB_STAT.txt', 'a') as fln:
      print(f'Критерий HI^2 для переменных \'{left}\' и \'{right}\'',
            file=fln)
      print(resx, file=fln)

  # Рассчет Cramer V по формуле
  nr = tabx.table_orig.shape[0]
  nc = tabx.table_orig.shape[1]
  N = tabx.table_orig.iloc[nr-1, nc-1]
  hisq = resx.statistic
  CrV = np.sqrt(hisq/(N*min((nr - 1, nc - 1))))
  with open('/content/drive/MyDrive/output/JOB_STAT.txt', 'a') as fln:
      print(f'Статистика Cramer V для переменных \'{left}\' и \'{right}\'',
            file=fln)
      print(CrV, file=fln)

arr = [['Race', 'Job Group']]
res = []
for left, right in arr:
  crtx = pd.crosstab(df_job_group_poor[left], df_job_group_poor[right], margins=True)
  crtx.columns.name = right
  crtx.index.name = left + '\\' +right
  tabx = sm.stats.Table(crtx)
# Из уже готовой таблицы сопряженности
# Создаем объект sm.stats.Table для проведения анализа
# В объекте находятся все необходимые статистики и дополнительные методы
  # Альтернативный вариант создания sm.stats.Table
  #table = sm.stats.Table.from_data(CA[['music', 'signal']])
  # Сохраняем полученные результаты
  # Ожидаемые частоты при независимости
  # Критерий хи квадрат для номинальных переменных
  resx = tabx.test_nominal_association()
  # Сохраняем результат в файле

  # Рассчет Cramer V по формуле
  nr = tabx.table_orig.shape[0]
  nc = tabx.table_orig.shape[1]
  N = tabx.table_orig.iloc[nr-1, nc-1]
  hisq = resx.statistic
  CrV = np.sqrt(hisq/(N*min((nr - 1, nc - 1))))
  res.append({'Связь': f'{arr[0][0]} - {arr[0][1]}',
              'Статистика 𝜒2': resx.statistic,
              '𝜒2 test p-value': resx.pvalue,
              'V  Крамера': CrV})

"""##Графический анализ"""

df_tmp = pd.DataFrame(df_job_group_poor['Job Group'].value_counts())
df_tmp.reset_index(inplace= True )
plt.bar(df_tmp['Job Group'], df_tmp['count'])
plt.xticks(rotation=90)
plt.savefig('/content/drive/MyDrive/graphics/jobs_bar_group.pdf', format='pdf')
plt.show()

dfn = df_job_group_poor.select_dtypes(include=["category"])
plt.figure(figsize=(15, 15)) # Дюймы
plt.subplots_adjust(wspace=0.5, hspace=0.1)
nplt = 0
nrow = dfn.shape[1]//2
ncol = nrow
tit = {'Senior':'Работа в школе','Job Group': 'Группа работы', 'Education Level': 'Уровень образования', 'Gender': "Пол", "Country": "Страна", "Race": "Раса"}
for nplt, s in enumerate(dfn.columns):
    ax = plt.subplot(nrow, ncol, nplt + 1)
    ftb = pd.crosstab(dfn[s], s)
    ftb.index.name = 'Категории'
    ftb.plot.pie(subplots=True, table=True, ax=ax, grid=True, legend=False)
    ax.set_title(tit[s], fontdict={'fontsize':15, 'color':'blue'}, loc='right')
plt.savefig('/content/drive/MyDrive/graphics/jobs_nom_poor.pdf', format='pdf')

dfn = df_job_group_poor.select_dtypes(include="category")
plt.figure(figsize=(15, 15)) # Дюймы
plt.subplots_adjust(wspace=0.5, hspace=1)
nplt = 0
nrow = dfn.shape[1]//2
ncol = nrow
tit = {'Senior':'Работа в школе','Job Group': 'Название работы', 'Education Level': 'Уровень образования', 'Gender': "Пол", "Country": "Страна", "Race": "Раса"}
for nplt, s in enumerate(dfn.columns):
    ax = plt.subplot(nrow, ncol, nplt + 1)
    ftb = pd.crosstab(dfn[s], s)
    ftb.index.name = 'Категории'
    ftb.plot.bar(subplots=True, table=False, ax=ax, grid=True, legend=False, label='')
    ax.set_title(tit[s], fontdict={'fontsize':15, 'color':'blue'}, loc='right')
plt.savefig('/content/drive/MyDrive/graphics/jobs_bar_poor.pdf', format='pdf')

fig, axes = plt.subplots(ncols=5, nrows=3, figsize=(20, 20))
cols = nom_vals
for i, (left, right) in enumerate(combinations(cols.columns, 2)):
  sns.histplot(data=df_job_group_poor, x=left, hue=right, ax=axes[i%3][i%5], multiple="stack")
  axes[i%3][i%5].tick_params(axis='x', rotation=90)
fig.subplots_adjust(wspace=0.3, hspace=0.5)
plt.savefig('/content/drive/MyDrive/graphics/jobs_combo_poor.pdf', format='pdf')
plt.tight_layout()
plt.show()

# Отбор имен качественных переменных
cols = df_job_group_poor.select_dtypes(include=['category'])
cols = cols.columns
# Количество графиков в столбце
nrow = len(cols) # Количество переменных в cols
fig, ax_lst = plt.subplots(nrow, 1, figsize=(15, 15)) # Дюймы
for nplt, s in enumerate(cols):
# Доверительные интервалы строятся методом бутстрепа
    df_job_group_poor.boxplot(column='Salary', by=s, ax=ax_lst[nplt], grid=True, notch=True,
                bootstrap=40, showmeans=True, color=None)
    ax_lst[nplt].tick_params(axis='x', rotation=45)
fig.subplots_adjust(wspace=0.3, hspace=2.5)
# Общая подпись к графикам
fig.suptitle('Категоризированные диагарммы Бокса-Вискера')
plt.savefig('/content/drive/MyDrive/graphics/job_qqdep_poor.pdf', format='pdf')
plt.show()

dfn = df_job_group_poor.select_dtypes(include=['float64', 'int'])
nrow = dfn.shape[1] - 1 # Учитываем, что одна переменная целевая - ось 'Y'
fig, ax_lst = plt.subplots(nrow, 1)
fig.figsize=(15, 9) # Дюймы
nplt = -1
for s in dfn.columns[:-1]: # Последняя переменная - целевая ('Y')
    nplt += 1
    dfn.plot.scatter(s, 'Salary', ax=ax_lst[nplt])
    ax_lst[nplt].grid(visible=True)
    ax_lst[nplt].set_title(f'Связь зарплаты с {s}')
fig.subplots_adjust(wspace=1, hspace=0.9)
"""
Общая подпись к графикам
Используем форматированные 'f'-строки
{} - позиция для подстановки значения
"""
fig.suptitle(f'Связь зарплаты с {list(dfn.columns[:-1])}')
plt.savefig('/content/drive/MyDrive/graphics/job_scat_poor.pdf', format='pdf')
plt.show()

"""##Моделирование"""

import numpy as np
import pandas as pd
import matplotlib as mpl
import matplotlib.pyplot as plt

import statsmodels.api as sm
# Читаем и преобразуем данные
JB = df_job_group_poor.copy()
# Разбиение данных на тренировочное и тестовое множество
# frac- доля данных в тренировочном множестве
# random_state - для повторного отбора тех же элементов
JB_train = JB.sample(frac=0.8, random_state=42)
# Символ ~ обозначает отрицание (not)
JB_test = JB.loc[~JB.index.isin(JB_train.index)]

# Будем накапливать данные о качестве постреонных моделей
# Используем  adjR^2 и AIC
mq = pd.DataFrame([], columns=['R^2', 'adjR^2', 'AIC']) # Данные о качестве
test_results = pd.DataFrame(None, columns=["Модель", "RMSE", "AE", "Доверительная вероятность"])

# Формируем целевую переменную
Y = JB_train['Salary']
# Формируем фиктивные (dummy) переменные для всех качественных переменных
DUM = pd.get_dummies(JB_train[['Gender', 'Education Level', 'Job Group', 'Senior']])
# Выбираем переменные для уровней, которые войдут в модель
# Будет исключен один - базовый. ВЛияние включенных уровней на зависимую
# переменную отсчитывается от него

DUM = DUM[['Gender_Female', 'Education Level_Bachelor Degree', 'Education Level_Master Degree', 'Education Level_Phd', 'Job Group_job_analyze', 'Job Group_job_control', 'Job Group_job_consult', 'Job Group_job_creativity', 'Job Group_job_marketing', 'Job Group_job_science', 'Job Group_job_technology', 'Senior_Yes']]

# Формируем pandas.DataFramee содержащий матрицу X объясняющих переменных
# Добавляем слева фиктивные переменные
X = pd.concat([DUM, JB_train[['Age', 'Years of Experience']]], axis=1)
# Добавляем переменную равную единице для учета константы
X = sm.add_constant(X)
X = X.astype({'const':'int64'}) # Сокращаем место для хранения константы
# Формируем объект, содержащй все исходные данные и методы для оценивания
linreg00 = sm.OLS(Y,X.astype(float))
# Оцениваем модель
fitmod00 = linreg00.fit()
# Сохраняем результаты оценки в файл
with open('/content/drive/MyDrive/output/JOB_STAT.txt', 'a') as fln:
    print('\n ****** Оценка базовой модели ******',
          file=fln)
    print(fitmod00.summary(), file=fln)

X = X.replace({False: 0, True : 1})

# Проверяем степень мультиколлинеарности только базовой модели
from statsmodels.stats.outliers_influence import variance_inflation_factor
vif = pd.DataFrame() # Для хранения
X_q = X.select_dtypes(include='int64')# Только количественные регрессоры
vif["vars"] = X_q.columns
vif["VIF"] = [variance_inflation_factor(X_q.values, i)
              for i in range(X_q.shape[1])]
# Сохраняем полученные результаты
with pd.ExcelWriter('/content/drive/MyDrive/output/JOB_STAT.xlsx', engine="openpyxl",
                    if_sheet_exists='overlay', mode='a') as wrt:
    vif.to_excel(wrt, sheet_name='vif')

# Проверяем гетероскедастичность базовой модели
# помощью коритерия White(а) и F критерия
from statsmodels.stats.diagnostic import het_white
e = fitmod00.resid
WHT = pd.DataFrame(het_white(e, X), index= ['LM', 'LM_P', 'F', 'F_P'])
# Сохраняем полученные результаты
with pd.ExcelWriter('/content/drive/MyDrive/output/JOB_STAT.xlsx', engine="openpyxl",
                    if_sheet_exists='overlay', mode='a') as wrt:
    WHT.to_excel(wrt, sheet_name='het')

# Сохраняем данные о качестве модели
q = pd.DataFrame([fitmod00.rsquared, fitmod00.rsquared_adj, fitmod00.aic],
                 index=['R^2', 'adjR^2', 'AIC'], columns=['hyp_base']).T
mq = pd.concat([mq, q])

"""Уберем Years of Expirience"""

X_1 = X.drop('Years of Experience', axis=1)
# Формируем объект, содержащий все исходные данные и методы для оценивания
linreg10 = sm.OLS(Y, X_1)
# Оцениваем модель
fitmod10 = linreg10.fit()
# Сохраняем результаты оценки в файл
with open('/content/drive/MyDrive/output/JOB_STAT.txt', 'a') as fln:
    print('\n ****** Оценка базовой модели ******',
          file=fln)
    print(fitmod10.summary(), file=fln)

# Сохраняем данные о качестве модели
q = pd.DataFrame([fitmod10.rsquared, fitmod10.rsquared_adj, fitmod10.aic],
                 index=['R^2', 'adjR^2', 'AIC'], columns=['hyp_base_mod1']).T
mq = pd.concat([mq, q])

# Формируем целевую переменную
Y = JB_train['Salary']
# Формируем фиктивные (dummy) переменные для всех качественных переменных
DUM = pd.get_dummies(JB_train[['Gender', 'Education Level', 'Job Group', 'Senior']])
# Выбираем переменные для уровней, которые войдут в модель
# Будет исключен один - базовый. ВЛияние включенных уровней на зависимую
# переменную отсчитывается от него

DUM = DUM[['Gender_Female', 'Education Level_Bachelor Degree', 'Education Level_Master Degree', 'Education Level_Phd', 'Job Group_job_analyze', 'Job Group_job_client', 'Job Group_job_consult', 'Job Group_job_creativity', 'Job Group_job_marketing', 'Job Group_job_science', 'Job Group_job_technology', 'Senior_Yes']]

# Формируем pandas.DataFramee содержащий матрицу X объясняющих переменных
# Добавляем слева фиктивные переменные
X = pd.concat([DUM, JB_train[['Age']]], axis=1)
# Добавляем переменную равную единице для учета константы
X = sm.add_constant(X)
X = X.astype({'const':'int64'}) # Сокращаем место для хранения константы
# Формируем объект, содержащй все исходные данные и методы для оценивания
linreg10 = sm.OLS(Y,X.astype(float))
# Оцениваем модель
fitmod10 = linreg10.fit()
# Сохраняем результаты оценки в файл
with open('/content/drive/MyDrive/output/JOB_STAT.txt', 'a') as fln:
    print('\n ****** Оценка базовой модели ******',
          file=fln)
    print(fitmod10.summary(), file=fln)

X = X.replace({False: 0, True : 1})

# Проверяем степень мультиколлинеарности только базовой модели
from statsmodels.stats.outliers_influence import variance_inflation_factor
vif = pd.DataFrame() # Для хранения
X_q = X.select_dtypes(include='int64')# Только количественные регрессоры
vif["vars"] = X_q.columns
vif["VIF"] = [variance_inflation_factor(X_q.values, i)
              for i in range(X_q.shape[1])]
# Сохраняем полученные результаты
with pd.ExcelWriter('/content/drive/MyDrive/output/JOB_STAT.xlsx', engine="openpyxl",
                    if_sheet_exists='overlay', mode='a') as wrt:
    vif.to_excel(wrt, sheet_name='vif_YoE')

# Проверяем гетероскедастичность базовой модели
# помощью коритерия White(а) и F критерия
from statsmodels.stats.diagnostic import het_white
e = fitmod10.resid
WHT = pd.DataFrame(het_white(e, X), index= ['LM', 'LM_P', 'F', 'F_P'])
# Сохраняем полученные результаты
with pd.ExcelWriter('/content/drive/MyDrive/output/JOB_STAT.xlsx', engine="openpyxl",
                    if_sheet_exists='overlay', mode='a') as wrt:
    WHT.to_excel(wrt, sheet_name='het_YoE')

"""Уберем Age"""

X_1 = X.drop('Age', axis=1)
# Формируем объект, содержащий все исходные данные и методы для оценивания
linreg11 = sm.OLS(Y, X_1)
# Оцениваем модель
fitmod11 = linreg11.fit()
# Сохраняем результаты оценки в файл
with open('/content/drive/MyDrive/output/JOB_STAT.txt', 'a') as fln:
    print('\n ****** Оценка базовой модели ******',
          file=fln)
    print(fitmod11.summary(), file=fln)

# Сохраняем данные о качестве модели
q = pd.DataFrame([fitmod11.rsquared, fitmod11.rsquared_adj, fitmod11.aic],
                 index=['R^2', 'adjR^2', 'AIC'], columns=['hyp_base_mod2']).T
mq = pd.concat([mq, q])

# Формируем целевую переменную
Y = JB_train['Salary']
# Формируем фиктивные (dummy) переменные для всех качественных переменных
DUM = pd.get_dummies(JB_train[['Gender', 'Education Level', 'Job Group', 'Senior']])
# Выбираем переменные для уровней, которые войдут в модель
# Будет исключен один - базовый. ВЛияние включенных уровней на зависимую
# переменную отсчитывается от него

DUM = DUM[['Gender_Female', 'Education Level_Bachelor Degree', 'Education Level_Master Degree', 'Education Level_Phd', 'Job Group_job_analyze', 'Job Group_job_client', 'Job Group_job_consult', 'Job Group_job_creativity', 'Job Group_job_marketing', 'Job Group_job_science', 'Job Group_job_technology', 'Senior_Yes']]

# Формируем pandas.DataFramee содержащий матрицу X объясняющих переменных
# Добавляем слева фиктивные переменные
X = pd.concat([DUM, JB_train[['Years of Experience']]], axis=1)
# Добавляем переменную равную единице для учета константы
X = sm.add_constant(X)
X = X.astype({'const':'int64'}) # Сокращаем место для хранения константы
# Формируем объект, содержащй все исходные данные и методы для оценивания
linreg11 = sm.OLS(Y,X.astype(float))
# Оцениваем модель
fitmod11 = linreg11.fit()
# Сохраняем результаты оценки в файл
with open('/content/drive/MyDrive/output/JOB_STAT.txt', 'a') as fln:
    print('\n ****** Оценка базовой модели ******',
          file=fln)
    print(fitmod11.summary(), file=fln)

X = X.replace({False: 0, True : 1})

# Проверяем степень мультиколлинеарности только базовой модели
from statsmodels.stats.outliers_influence import variance_inflation_factor
vif = pd.DataFrame() # Для хранения
X_q = X.select_dtypes(include='int64')# Только количественные регрессоры
vif["vars"] = X_q.columns
vif["VIF"] = [variance_inflation_factor(X_q.values, i)
              for i in range(X_q.shape[1])]
# Сохраняем полученные результаты
with pd.ExcelWriter('/content/drive/MyDrive/output/JOB_STAT.xlsx', engine="openpyxl",
                    if_sheet_exists='overlay', mode='a') as wrt:
    vif.to_excel(wrt, sheet_name='vif_A')

# Проверяем гетероскедастичность базовой модели
# помощью коритерия White(а) и F критерия
from statsmodels.stats.diagnostic import het_white
e = fitmod11.resid
WHT = pd.DataFrame(het_white(e, X), index= ['LM', 'LM_P', 'F', 'F_P'])
# Сохраняем полученные результаты
with pd.ExcelWriter('/content/drive/MyDrive/output/JOB_STAT.xlsx', engine="openpyxl",
                    if_sheet_exists='overlay', mode='a') as wrt:
    WHT.to_excel(wrt, sheet_name='het_A')

"""##Гипотеза №1"""

X_1 = X.copy()
linreg01 = sm.OLS(Y,X_1)
fitmod01 = linreg01.fit()
# Сохраняем результаты оценки в файл
with open('/content/drive/MyDrive/output/JOB_STAT.txt', 'a') as fln:
    print('\n ****** Оценка базовой модели 1 ******',
          file=fln)
    print(fitmod01.summary(), file=fln)

# Сохраняем данные о качестве модели
q = pd.DataFrame([fitmod01.rsquared, fitmod01.rsquared_adj, fitmod01.aic],
                 index=['R^2', 'adjR^2', 'AIC'], columns=['hyp_1']).T
mq = pd.concat([mq, q])

"""##Гипотеза №2"""

X_2 = X.copy()
X_2['Phd_F'] = X_2['Education Level_Phd'] * X_2['Gender_Female']
X_2['Not_Phd_F'] = (~X_2['Education Level_Phd']) * X_2['Gender_Female']
#X_2 = X_2.drop(columns=['Gender_Female', 'Education Level_Phd',
#                        'Education Level_Master Degree', 'Education Level_Bachelor Degree'])
linreg02 = sm.OLS(Y,X_2)
fitmod02 = linreg02.fit()
# Сохраняем результаты оценки в файл
with open('/content/drive/MyDrive/output/JOB_STAT.txt', 'a') as fln:
    print('\n ****** Оценка базовой модели 2 ******',
          file=fln)
    print(fitmod02.summary(), file=fln)

# Сохраняем данные о качестве модели
q = pd.DataFrame([fitmod02.rsquared, fitmod02.rsquared_adj, fitmod02.aic],
                 index=['R^2', 'adjR^2', 'AIC'], columns=['hyp_2']).T
mq = pd.concat([mq, q])

"""##Гипотеза №3"""

X_3 = X.copy()
tmp = X_3['Years of Experience'] <= 5
X_3['Female_YoE'] = tmp * X_3['Gender_Female']
X_3['Male_YoE'] = tmp * (~X_3['Gender_Female'])
#X_3 = X_3.drop(columns=['Gender_Female','Years of Experience'])
linreg03 = sm.OLS(Y,X_3)
fitmod03 = linreg03.fit()
# Сохраняем результаты оценки в файл
with open('/content/drive/MyDrive/output/JOB_STAT.txt', 'a') as fln:
    print('\n ****** Оценка базовой модели 3 ******',
          file=fln)
    print(fitmod03.summary(), file=fln)

# Сохраняем данные о качестве модели
q = pd.DataFrame([fitmod03.rsquared, fitmod03.rsquared_adj, fitmod03.aic],
                 index=['R^2', 'adjR^2', 'AIC'], columns=['hyp_3']).T
mq = pd.concat([mq, q])

fig, axs = plt.subplots(1, 2, figsize=(12, 6))
tmp = df_job_group_poor[df_job_group_poor['Gender'] == 'Female']
sns.histplot(tmp['Years of Experience'], ax=axs[0])
axs[0].set_title("Female")

tmp_1 = df_job_group_poor[df_job_group_poor['Gender'] == 'Male']
sns.histplot(tmp_1['Years of Experience'], ax=axs[1])
axs[1].set_title("Male")

plt.tight_layout()
plt.savefig('/content/drive/MyDrive/graphics/jobs_bar_fm.pdf', format='pdf')

plt.show()

"""##Итоговая модель"""

X_4 = X.copy()
tmp = X_4['Years of Experience'] <= 3
X_4['Female_YoE'] = tmp * X_4['Gender_Female']
X_4['Male_YoE'] = tmp * (~X_4['Gender_Female'])
X_4['Phd_F'] = X_4['Education Level_Phd'] * X_4['Gender_Female']
X_4['Not_Phd_F'] = (~X_4['Education Level_Phd']) * X_4['Gender_Female']
linreg04 = sm.OLS(Y,X_4)
fitmod04 = linreg04.fit()
# Сохраняем результаты оценки в файл
with open('/content/drive/MyDrive/output/JOB_STAT.txt', 'a') as fln:
    print('\n ****** Оценка итоговой модели ******',
          file=fln)
    print(fitmod04.summary(), file=fln)

# Сохраняем данные о качестве модели
q = pd.DataFrame([fitmod04.rsquared, fitmod04.rsquared_adj, fitmod04.aic],
                 index=['R^2', 'adjR^2', 'AIC'], columns=['hyp_final']).T
mq = pd.concat([mq, q])

"""Оценка итоговой модели"""

# Проверяем степень мультиколлинеарности только базовой модели
from statsmodels.stats.outliers_influence import variance_inflation_factor
vif = pd.DataFrame() # Для хранения
X_q = X_4.select_dtypes(include='int64')# Только количественные регрессоры
vif["vars"] = X_q.columns
vif["VIF"] = [variance_inflation_factor(X_q.values, i)
              for i in range(X_q.shape[1])]
# Сохраняем полученные результаты
with pd.ExcelWriter('/content/drive/MyDrive/output/JOB_STAT.xlsx', engine="openpyxl",
                    if_sheet_exists='overlay', mode='a') as wrt:
    vif.to_excel(wrt, sheet_name='vif_final')

# Проверяем гетероскедастичность базовой модели
# помощью коритерия White(а) и F критерия
from statsmodels.stats.diagnostic import het_white
e = fitmod04.resid
WHT = pd.DataFrame(het_white(e, X_4), index= ['LM', 'LM_P', 'F', 'F_P'])
# Сохраняем полученные результаты
with pd.ExcelWriter('/content/drive/MyDrive/output/JOB_STAT.xlsx', engine="openpyxl",
                    if_sheet_exists='overlay', mode='a') as wrt:
    WHT.to_excel(wrt, sheet_name='het_final')

"""Оценка модифицированной модели (удалим переменную Not_Phd_F)"""

X_mod = X_4.drop('Not_Phd_F', axis=1)
# Формируем объект, содержащий все исходные данные и методы для оценивания
linreg41 = sm.OLS(Y, X_mod)
# Оцениваем модель
fitmod41 = linreg41.fit()
# Сохраняем результаты оценки в файл
with open('/content/drive/MyDrive/output/JOB_STAT.txt', 'a') as fln:
    print('\n ****** Оценка итоговой модели 1 ******',
          file=fln)
    print(fitmod41.summary(), file=fln)

# Сохраняем данные о качестве модели
q = pd.DataFrame([fitmod41.rsquared, fitmod41.rsquared_adj, fitmod41.aic],
                 index=['R^2', 'adjR^2', 'AIC'], columns=['hyp_final_mod_PF']).T
mq = pd.concat([mq, q])

# Проверяем степень мультиколлинеарности только базовой модели
from statsmodels.stats.outliers_influence import variance_inflation_factor
vif = pd.DataFrame() # Для хранения
X_q = X_mod.select_dtypes(include='int64')# Только количественные регрессоры
vif["vars"] = X_q.columns
vif["VIF"] = [variance_inflation_factor(X_q.values, i)
              for i in range(X_q.shape[1])]
# Сохраняем полученные результаты
with pd.ExcelWriter('/content/drive/MyDrive/output/JOB_STAT.xlsx', engine="openpyxl",
                    if_sheet_exists='overlay', mode='a') as wrt:
    vif.to_excel(wrt, sheet_name='vif_final_mod_PF')

# Проверяем гетероскедастичность базовой модели
# помощью коритерия White(а) и F критерия
from statsmodels.stats.diagnostic import het_white
e = fitmod04.resid
WHT = pd.DataFrame(het_white(e, X_mod), index= ['LM', 'LM_P', 'F', 'F_P'])
# Сохраняем полученные результаты
with pd.ExcelWriter('/content/drive/MyDrive/output/JOB_STAT.xlsx', engine="openpyxl",
                    if_sheet_exists='overlay', mode='a') as wrt:
    WHT.to_excel(wrt, sheet_name='het_final_mod_PF')

"""Оценка модифицированной модели (удалим переменную Male_YoE)"""

X_mod = X_4.drop('Male_YoE', axis=1)
# Формируем объект, содержащий все исходные данные и методы для оценивания
linreg42 = sm.OLS(Y, X_mod)
# Оцениваем модель
fitmod42 = linreg01.fit()
# Сохраняем результаты оценки в файл
with open('/content/drive/MyDrive/output/JOB_STAT.txt', 'a') as fln:
    print('\n ****** Оценка итоговой модели 2 ******',
          file=fln)
    print(fitmod42.summary(), file=fln)

# Сохраняем данные о качестве модели
q = pd.DataFrame([fitmod42.rsquared, fitmod42.rsquared_adj, fitmod42.aic],
                 index=['R^2', 'adjR^2', 'AIC'], columns=['hyp_final_mod_MYoE']).T
mq = pd.concat([mq, q])

# Проверяем степень мультиколлинеарности только базовой модели
from statsmodels.stats.outliers_influence import variance_inflation_factor
vif = pd.DataFrame() # Для хранения
X_q = X_mod.select_dtypes(include='int64')# Только количественные регрессоры
vif["vars"] = X_q.columns
vif["VIF"] = [variance_inflation_factor(X_q.values, i)
              for i in range(X_q.shape[1])]
# Сохраняем полученные результаты
with pd.ExcelWriter('/content/drive/MyDrive/output/JOB_STAT.xlsx', engine="openpyxl",
                    if_sheet_exists='overlay', mode='a') as wrt:
    vif.to_excel(wrt, sheet_name='vif_final_mod_MYoE')

# Проверяем гетероскедастичность базовой модели
# помощью коритерия White(а) и F критерия
from statsmodels.stats.diagnostic import het_white
e = fitmod42.resid
WHT = pd.DataFrame(het_white(e, X_mod), index= ['LM', 'LM_P', 'F', 'F_P'])
# Сохраняем полученные результаты
with pd.ExcelWriter('/content/drive/MyDrive/output/JOB_STAT.xlsx', engine="openpyxl",
                    if_sheet_exists='overlay', mode='a') as wrt:
    WHT.to_excel(wrt, sheet_name='het_final_mod_MYoE')

"""Оценка модифицированной модели (удалим переменную Female_YoE)"""

X_mod = X_4.drop('Female_YoE', axis=1)
# Формируем объект, содержащий все исходные данные и методы для оценивания
linreg43 = sm.OLS(Y, X_mod)
# Оцениваем модель
fitmod43 = linreg01.fit()
# Сохраняем результаты оценки в файл
with open('/content/drive/MyDrive/output/JOB_STAT.txt', 'a') as fln:
    print('\n ****** Оценка итоговой модели 3 ******',
          file=fln)
    print(fitmod01.summary(), file=fln)

# Сохраняем данные о качестве модели
q = pd.DataFrame([fitmod43.rsquared, fitmod43.rsquared_adj, fitmod43.aic],
                 index=['R^2', 'adjR^2', 'AIC'], columns=['hyp_final_mod_FYoE']).T
mq = pd.concat([mq, q])

# Проверяем степень мультиколлинеарности только базовой модели
from statsmodels.stats.outliers_influence import variance_inflation_factor
vif = pd.DataFrame() # Для хранения
X_q = X_mod.select_dtypes(include='int64')# Только количественные регрессоры
vif["vars"] = X_q.columns
vif["VIF"] = [variance_inflation_factor(X_q.values, i)
              for i in range(X_q.shape[1])]
# Сохраняем полученные результаты
with pd.ExcelWriter('/content/drive/MyDrive/output/JOB_STAT.xlsx', engine="openpyxl",
                    if_sheet_exists='overlay', mode='a') as wrt:
    vif.to_excel(wrt, sheet_name='vif_final_mod_FYoE')

# Проверяем гетероскедастичность базовой модели
# помощью коритерия White(а) и F критерия
from statsmodels.stats.diagnostic import het_white
e = fitmod43.resid
WHT = pd.DataFrame(het_white(e, X_mod), index= ['LM', 'LM_P', 'F', 'F_P'])
# Сохраняем полученные результаты
with pd.ExcelWriter('/content/drive/MyDrive/output/JOB_STAT.xlsx', engine="openpyxl",
                    if_sheet_exists='overlay', mode='a') as wrt:
    WHT.to_excel(wrt, sheet_name='het_final_mod_FYoE')

Y_test = JB_test['Salary']
DUM = pd.get_dummies(JB_test[['Gender', 'Education Level', 'Job Group', 'Senior']])
# Выбираем переменные для уровней, которые войдут в модель
# Будет исключен один - базовый. ВЛияние включенных уровней на зависимую
# переменную отсчитывается от него
DUM = DUM[['Gender_Female', 'Education Level_Bachelor Degree', 'Education Level_Master Degree', 'Education Level_Phd', 'Job Group_job_analyze', 'Job Group_job_client', 'Job Group_job_consult', 'Job Group_job_creativity', 'Job Group_job_marketing', 'Job Group_job_science', 'Job Group_job_technology', 'Senior_Yes']]
# Формируем pandas.DataFramee содержащий матрицу X объясняющих переменных
# Добавляем слева фиктивные переменные
X_test = pd.concat([DUM, JB_test[['Years of Experience']]], axis=1)
# Добавляем переменную равную единице для учета константы
X_test = sm.add_constant(X_test)
X_test = X_test.astype({'const':'int64'})
# Генерация предсказаний на тестовом множестве
pred_ols = fitmod01.get_prediction(X_test.astype(float))
# Генерация доверительных интервалов с доверительной вероятностью alpha
frm = pred_ols.summary_frame(alpha=0.05)
iv_l = frm["obs_ci_lower"] # Нижняя граница доверительных интервалов
iv_u = frm["obs_ci_upper"] # Верхняя граница доверительных интервалов
fv = frm['mean'] # Предсказанное значение целевой переменной
# Построение графиков
mse = np.sqrt((Y_test - fv).pow(2).sum())/len(Y_test)
mae = np.sum(np.abs(Y_test - fv))

test_results.loc[len(test_results.index)] =["Базовая", mse, mae, 1 - len(Y_test[(Y_test<frm["obs_ci_lower"])|(Y_test>frm["obs_ci_upper"])])/len(Y_test)]

name = 'Years of Experience' # Имя переменной относительно которой строим прогноз
Z = X_test.loc[:, name]
dfn = pd.DataFrame([Z, Y_test, fv, iv_u, iv_l]).T
dfn = dfn.sort_values(by=name)
fig, ax = plt.subplots(figsize=(8, 6))
for z in dfn.columns[1:]:
    dfn.plot(x=dfn.columns[0], y=z, ax=ax)
ax.legend(loc="best")
plt.savefig('/content/drive/MyDrive/graphics/jobs_obs.pdf', format='pdf')
plt.show()

Y_test = JB_test['Salary']
DUM = pd.get_dummies(JB_test[['Gender', 'Education Level', 'Job Group', 'Senior']])
# Выбираем переменные для уровней, которые войдут в модель
# Будет исключен один - базовый. ВЛияние включенных уровней на зависимую
# переменную отсчитывается от него
DUM = DUM[['Gender_Female', 'Education Level_Bachelor Degree', 'Education Level_Master Degree', 'Education Level_Phd', 'Job Group_job_analyze', 'Job Group_job_client', 'Job Group_job_consult', 'Job Group_job_creativity', 'Job Group_job_marketing', 'Job Group_job_science', 'Job Group_job_technology', 'Senior_Yes']]
# Формируем pandas.DataFramee содержащий матрицу X объясняющих переменных
# Добавляем слева фиктивные переменные
X_test = pd.concat([DUM, JB_test[['Years of Experience']]], axis=1)
X_test['Phd_F'] = X_test['Education Level_Phd'] * X_test['Gender_Female']
X_test['Not_Phd_F'] = (~X_test['Education Level_Phd']) * X_test['Gender_Female']
# Добавляем переменную равную единице для учета константы
X_test = sm.add_constant(X_test)
X_test = X_test.astype({'const':'int64'})
# Генерация предсказаний на тестовом множестве
pred_ols = fitmod02.get_prediction(X_test.astype(float))

frm = pred_ols.summary_frame(alpha=0.05)
iv_l = frm["obs_ci_lower"] # Нижняя граница доверительных интервалов
iv_u = frm["obs_ci_upper"] # Верхняя граница доверительных интервалов
fv = frm['mean'] # Предсказанное значение целевой переменной
# Построение графиков
mse = np.sqrt((Y_test - fv).pow(2).sum())/len(Y_test)
mae = np.sum(np.abs(Y_test - fv))
test_results.loc[len(test_results.index)] = ["Промежуточная 1", mse, mae, 1 - len(Y_test[(Y_test<frm["obs_ci_lower"])|(Y_test>frm["obs_ci_upper"])])/len(Y_test)]

Y_test = JB_test['Salary']
DUM = pd.get_dummies(JB_test[['Gender', 'Education Level', 'Job Group', 'Senior']])
# Выбираем переменные для уровней, которые войдут в модель
# Будет исключен один - базовый. ВЛияние включенных уровней на зависимую
# переменную отсчитывается от него
DUM = DUM[['Gender_Female', 'Education Level_Bachelor Degree', 'Education Level_Master Degree', 'Education Level_Phd', 'Job Group_job_analyze', 'Job Group_job_client', 'Job Group_job_consult', 'Job Group_job_creativity', 'Job Group_job_marketing', 'Job Group_job_science', 'Job Group_job_technology', 'Senior_Yes']]
# Формируем pandas.DataFramee содержащий матрицу X объясняющих переменных
# Добавляем слева фиктивные переменные
X_test = pd.concat([DUM, JB_test[['Years of Experience']]], axis=1)
tmp = X_test['Years of Experience'] <= 3
X_test['Female_YoE'] = tmp * X_test['Gender_Female']
X_test['Male_YoE'] = tmp * (~X_test['Gender_Female'])
# Добавляем переменную равную единице для учета константы
X_test = sm.add_constant(X_test)
X_test = X_test.astype({'const':'int64'})
# Генерация предсказаний на тестовом множестве
pred_ols = fitmod03.get_prediction(X_test.astype(float))

frm = pred_ols.summary_frame(alpha=0.05)
iv_l = frm["obs_ci_lower"] # Нижняя граница доверительных интервалов
iv_u = frm["obs_ci_upper"] # Верхняя граница доверительных интервалов
fv = frm['mean'] # Предсказанное значение целевой переменной
# Построение графиков
mse = np.sqrt((Y_test - fv).pow(2).sum())/len(Y_test)
mae = np.sum(np.abs(Y_test - fv))
test_results.loc[len(test_results.index)] = ["Промежуточная 2", mse, mae, 1 - len(Y_test[(Y_test<frm["obs_ci_lower"])|(Y_test>frm["obs_ci_upper"])])/len(Y_test)]

Y_test = JB_test['Salary']
DUM = pd.get_dummies(JB_test[['Gender', 'Education Level', 'Job Group', 'Senior']])
# Выбираем переменные для уровней, которые войдут в модель
# Будет исключен один - базовый. ВЛияние включенных уровней на зависимую
# переменную отсчитывается от него
DUM = DUM[['Gender_Female', 'Education Level_Bachelor Degree', 'Education Level_Master Degree', 'Education Level_Phd', 'Job Group_job_analyze', 'Job Group_job_client', 'Job Group_job_consult', 'Job Group_job_creativity', 'Job Group_job_marketing', 'Job Group_job_science', 'Job Group_job_technology', 'Senior_Yes']]
# Формируем pandas.DataFramee содержащий матрицу X объясняющих переменных
# Добавляем слева фиктивные переменные
X_test = pd.concat([DUM, JB_test[['Years of Experience']]], axis=1)
tmp = X_test['Years of Experience'] <= 3
X_test['Female_YoE'] = tmp * X_test['Gender_Female']
X_test['Male_YoE'] = tmp * (~X_test['Gender_Female'])
X_test['Phd_F'] = X_test['Education Level_Phd'] * X_test['Gender_Female']
X_test['Not_Phd_F'] = (~X_test['Education Level_Phd']) * X_test['Gender_Female']
# Добавляем переменную равную единице для учета константы
X_test = sm.add_constant(X_test)
X_test = X_test.astype({'const':'int64'})
# Генерация предсказаний на тестовом множестве
pred_ols = fitmod04.get_prediction(X_test.astype(float))

frm = pred_ols.summary_frame(alpha=0.05)
iv_l = frm["obs_ci_lower"] # Нижняя граница доверительных интервалов
iv_u = frm["obs_ci_upper"] # Верхняя граница доверительных интервалов
fv = frm['mean'] # Предсказанное значение целевой переменной
# Построение графиков
mse = np.sqrt((Y_test - fv).pow(2).sum())/len(Y_test)
mae = np.sum(np.abs(Y_test - fv))
test_results.loc[len(test_results.index)] = ["Итоговая", mse, mae, 1 - len(Y_test[(Y_test<frm["obs_ci_lower"])|(Y_test>frm["obs_ci_upper"])])/len(Y_test)]

Y_test = JB_test['Salary']
DUM = pd.get_dummies(JB_test[['Gender', 'Education Level', 'Job Group', 'Senior']])
# Выбираем переменные для уровней, которые войдут в модель
# Будет исключен один - базовый. ВЛияние включенных уровней на зависимую
# переменную отсчитывается от него
DUM = DUM[['Gender_Female', 'Education Level_Bachelor Degree', 'Education Level_Master Degree', 'Education Level_Phd', 'Job Group_job_analyze', 'Job Group_job_client', 'Job Group_job_consult', 'Job Group_job_creativity', 'Job Group_job_marketing', 'Job Group_job_science', 'Job Group_job_technology', 'Senior_Yes']]
# Формируем pandas.DataFramee содержащий матрицу X объясняющих переменных
# Добавляем слева фиктивные переменные
X_test = pd.concat([DUM, JB_test[['Years of Experience']]], axis=1)
tmp = X_test['Years of Experience'] <= 3
X_test['Female_YoE'] = tmp * X_test['Gender_Female']
X_test['Male_YoE'] = tmp * (~X_test['Gender_Female'])
X_test['Phd_F'] = X_test['Education Level_Phd'] * X_test['Gender_Female']
# Добавляем переменную равную единице для учета константы
X_test = sm.add_constant(X_test)
X_test = X_test.astype({'const':'int64'})
# Генерация предсказаний на тестовом множестве
pred_ols = fitmod41.get_prediction(X_test.astype(float))

frm = pred_ols.summary_frame(alpha=0.05)
iv_l = frm["obs_ci_lower"] # Нижняя граница доверительных интервалов
iv_u = frm["obs_ci_upper"] # Верхняя граница доверительных интервалов
fv = frm['mean'] # Предсказанное значение целевой переменной
#Подведение итогов
mse = np.sqrt((Y_test - fv).pow(2).sum())/len(Y_test)
mae = np.sum(np.abs(Y_test - fv))

test_results.loc[len(test_results.index)] = ["Финальная", mse, mae, 1 - len(Y_test[(Y_test<frm["obs_ci_lower"])|(Y_test>frm["obs_ci_upper"])])/len(Y_test)]
with pd.ExcelWriter('/content/drive/MyDrive/output/JOB_STAT.xlsx', engine="openpyxl",
                    if_sheet_exists='overlay', mode='a') as wrt:
    test_results.to_excel(wrt, sheet_name='Forecasts', index=False)

